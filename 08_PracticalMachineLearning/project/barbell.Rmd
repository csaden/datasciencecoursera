---
title: "Barbell Predictions"
author: "Chris Saden"
date: "June 19, 2014"
output: html_document
---

Load training and test sets.
```{r}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

**Examine the data set and variable names.**
```{r results='hide'}
names(training)
summary(training)
```

**Load libraries and create training and test set**
```{r}
library(caret)
library(kernlab)
set.seed(1234)

# Partition the training set into a training set 80% of values and a validation set 20% of values.

inTrain <- createDataPartition(y=training$classe,
                               p=.8, list=F)
trainSet <- training[inTrain, ]
valSet <- training[-inTrain, ]
```

**Variables to use for prediction.**

When determining predictors, I focused on using raw measurements from the sensor data (numerical and integer values). I removed factor variables and many of the summary statistics associated with the data such as averages, standard deviations, maxima and minima. 

```{r}
# Ignore the factor variables

keepVars <- sapply(training, function(x) class(x)=="integer" | class(x)=="numeric")
keepVars <- keepVars[which(keepVars)]
keepVars <- names(keepVars)


# Get rid of data points that include averages, variances, standard deviations, maximums, minimums, and amplitudes

remove <- grep("^avg|^var|^stddev|^max|^min|^ampl",
               keepVars, value=T)
keepVars <- keepVars[! keepVars %in% remove]

# get rid of identifiers like X, timestamps, and window number

keepVars <- keepVars[-c(1:4)]


# create smaller training and validation sets and add back the classe variable

trainSet <- trainSet[, c(keepVars, "classe")]
valSet <- valSet[, c(keepVars, "classe")]
```

In building a model to predict the classe variable, I first tried using a simple classification tree using the "rpart" method in the train function from the caret package. The accuracy on the validation set was only 50%, which was too low.

```{r}
# Classification Tree
modFit1 <- train(classe ~ .,
                data=trainSet,
                preProcess=c("center", "scale"),
                method="rpart")

print(modFit1$finalModel)
library(rattle)
fancyRpartPlot(modFit1$finalModel)

pred1 <- predict(modFit1, valSet)
confusionMatrix(pred1, valSet$classe)
```

Next, I attempted to create a random forest model by centering and scaling the data and by using an oob method in the trainControl option. Originally, I tried using a 10-fold and 3-fold cross validation approach in the trainControl option, however these models took a lot of time to build, and the error rates were slightly higher (1-5%) than the random forest approach. The code and output from these models was omitted to shorten the report.

**Train a random forest on the training set**
```{r}
set.seed(3495)
modFit <- train(classe ~ .,
                data=trainSet,
                preProcess=c("center", "scale"),
                method="rf",
                trControl=trainControl(method="oob"),
                prox=T)

print(modFit$finalModel)
```

The OOB estimate of in-sample error rate is 0.53%. Next, the random forest model was cross-validated using the 20% hold of values taken from the training set (aka the validation set, valSet)

**Predict the class of the validation set and check accuracy**
```{r}
pred <- predict(modFit, valSet)
confusionMatrix(pred, valSet$classe)
```

To calculate the out of error sample rate, I used the formula "1-accuracy" where accuracy is the "correctness of the model". That is to say, the classe values predicted by the predict function actually match the values of the classe variable in the validation set.

The OOB estimate of the out of sample error rate is 0.59% with 95% CI .37%-.88%.

Finally, I used the random forest model to predict the values of the classe variable in the test set.

**Predict the classe of the test set**
```{r}
testSet <- testing[ , keepVars]
testSet$classe <- predict(modFit, testSet)
```

**Write Answers to Files**
```{r}
answers <- as.character(testSet$classe)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```